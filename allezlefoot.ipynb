{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cosine similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity vect 1 : 99.86232150476508\n",
      "Cosine Similarity vect 2 : 98.8484825526468\n",
      "Cosine Similarity vect 3 : 54.950958527920655\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vect_1 = [5, 10, 9]    # 5x+10y+9z\n",
    "vect_2 = [6, 8, 7]    # 6x+8y+7z\n",
    "vect_3 = [10, 2, 1]    # 10x+2y+z\n",
    "ref_01 = [5, 9, 9]     # 5x+9y+9z\n",
    "\n",
    "vect2_1 = np.array(vect_1).reshape(1, -1)\n",
    "vect2_2 = np.array(vect_2).reshape(1, -1)\n",
    "vect2_3 = np.array(vect_3).reshape(1, -1)\n",
    "ref2_01 = np.array(ref_01).reshape(1, -1)\n",
    "\n",
    "sim_1 = cosine_similarity(vect2_1, ref2_01)\n",
    "sim_2 = cosine_similarity(vect2_2, ref2_01)\n",
    "sim_3 = cosine_similarity(vect2_3, ref2_01)\n",
    "\n",
    "print(\"Cosine Similarity vect 1 :\", sim_1[0, 0]*100)\n",
    "print(\"Cosine Similarity vect 2 :\", sim_2[0, 0]*100)\n",
    "print(\"Cosine Similarity vect 3 :\", sim_3[0, 0]*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lieux**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity pour  paul\n",
      "Cosine Similarity espace_anjou : 68.0\n",
      "Cosine Similarity latol pour : 93.12427797057535\n",
      "Cosine Similarity carrouf_saint_sersge : 66.43638388299196\n",
      "----------------------------\n",
      "Similarity pour  Marie\n",
      "Cosine Similarity espace_anjou : 91.5658572836824\n",
      "Cosine Similarity latol pour : 77.65485744279958\n",
      "Cosine Similarity carrouf_saint_sersge : 88.62922438980252\n",
      "----------------------------\n",
      "Similarity pour  Benedict\n",
      "Cosine Similarity espace_anjou : 63.39623465796166\n",
      "Cosine Similarity latol pour : 68.50683867618854\n",
      "Cosine Similarity carrouf_saint_sersge : 56.91644030368352\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "#x = shoppping homme\n",
    "#y = shopping femme\n",
    "#z = resto\n",
    "espace_anjou = np.array([6, 8, 5] ).reshape(1, -1)\n",
    "latol= np.array([8, 3, 7]).reshape(1, -1)\n",
    "carrouf_saint_sersge= np.array([3, 4, 2]  ).reshape(1, -1)\n",
    "\n",
    "paul = { \"name\": \"paul\",\n",
    "         \"vect\": np.array([10, 0, 5]).reshape(1, -1)}\n",
    "Marie = { \"name\": \"Marie\",\n",
    "        \"vect\": np.array([3, 10, 10]).reshape(1, -1)}\n",
    "Benedict = {\"name\": \"Benedict\",\n",
    "            \"vect\": np.array([0, 3, 10]).reshape(1, -1)}\n",
    "\n",
    "results=[[],[]]\n",
    "\n",
    "for i in [paul, Marie, Benedict]:\n",
    "\n",
    "\n",
    "    \n",
    "    print(\"Similarity pour \", i[\"name\"])\n",
    "    print(\"Cosine Similarity espace_anjou :\", cosine_similarity(i[\"vect\"], espace_anjou)[0, 0]*100)\n",
    "    print(\"Cosine Similarity latol pour :\", cosine_similarity(i[\"vect\"], latol)[0, 0]*100)\n",
    "    print(\"Cosine Similarity carrouf_saint_sersge :\", cosine_similarity(i[\"vect\"], carrouf_saint_sersge)[0, 0]*100)\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Torch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 1.94293320e-01 -2.10651219e-01 -2.45663583e-01  4.50096071e-01\n  2.51398236e-01 -8.25517178e-01  3.70970607e-01  4.05648261e-01\n  4.45635259e-01  3.17174196e-01 -7.37123668e-01  7.12277889e-01\n  8.31833124e-01 -9.75195885e-01 -4.67719913e-01 -5.42342328e-02\n -1.65470943e-01 -1.30574405e-02  1.67292401e-01 -2.00911969e-01\n  9.35625374e-01  7.70781755e-01  1.35033512e-02  1.65528715e-01\n  1.73180056e+00 -4.99150753e-01  2.14997843e-01 -3.55547547e-01\n -5.80278575e-01 -1.52904820e+00  9.06478047e-01  7.97619164e-01\n -1.28061736e+00 -4.37950157e-02  4.86372739e-01  8.81358564e-01\n -4.59378988e-01  4.17938560e-01  4.64622915e-01 -4.24909294e-01\n  1.23207617e+00  5.29266931e-02 -1.09578688e-02 -8.14341307e-02\n  7.00495690e-02  5.17972708e-01  9.88236010e-01  2.07783639e-01\n  4.26896989e-01  5.04319310e-01 -3.22461963e-01 -3.68990488e-02\n -2.64071584e-01  1.17840208e-01  7.79965937e-01  2.84064263e-01\n -1.03462243e+00 -4.13286686e-01  3.31757933e-01  2.21932039e-01\n  9.72830057e-02 -1.45220175e-01 -4.45241809e-01  5.39845467e-01\n -4.59513813e-01  1.76549464e-01 -2.38531828e-01 -3.91258746e-01\n -6.67483509e-01 -9.60243680e-03 -1.88307953e+00  4.92146552e-01\n  4.68064725e-01  7.14264929e-01 -1.00232089e+00 -1.33189440e+00\n -7.09219217e-01 -4.32485074e-01 -1.31902680e-01 -3.59311163e-01\n  2.43577417e-02 -1.20751277e-01  4.31555361e-02 -5.91750562e-01\n -3.01917922e-02 -4.84053195e-01 -7.25147367e-01  5.11856079e-02\n  6.28282487e-01  1.59070566e-01 -1.71613857e-01 -2.41314307e-01\n  6.95268035e-01 -1.21703339e+00 -7.92324021e-02  2.19056919e-01\n  9.64006186e-01  7.69332284e-03  5.19302368e-01 -1.02822995e+00\n  1.94025561e-02  7.05509186e-01 -9.62175786e-01 -6.19192421e-01\n -2.02194676e-01 -3.38242352e-01  3.22623551e-02  5.93251586e-01\n  2.08731461e-02  5.34945307e-03  6.92562342e-01  6.62296951e-01\n -6.91574454e-01  3.30411494e-01 -9.54753757e-01  1.27606437e-01\n -5.14088154e-01 -5.96677184e-01  9.99101102e-01 -1.97664574e-02\n -8.44280183e-01  1.63048059e-01 -1.88813284e-01  4.10677791e-01\n  4.86011297e-01  7.03580856e-01  2.21058279e-01  3.97054851e-01\n  2.45410308e-01 -1.18445230e+00 -3.54909569e-01 -6.23040855e-01\n -1.32707596e-01 -2.12662835e-02 -1.35669500e-01  3.76995742e-01\n  7.03804970e-01 -5.37166893e-01 -1.98757946e-01  4.30597663e-01\n  5.72494805e-01  1.40805796e-01 -2.17127442e-01 -3.26088220e-01\n -6.88603401e-01  6.94000065e-01  2.47398004e-01 -2.26765394e-01\n  4.00792480e-01 -1.49014980e-01 -1.20922662e-02  1.41874626e-01\n -2.62499660e-01 -8.40344667e-01  2.85539836e-01 -1.00684154e+00\n -2.89785147e-01 -5.88097751e-01 -4.90014702e-02 -1.09425284e-01\n  3.29142511e-01 -2.52799094e-01 -6.03153229e-01  1.12131730e-01\n -9.23459232e-02  1.15764700e-01  3.52418453e-01 -6.96424663e-01\n  1.69107497e-01 -1.13010816e-02  3.44364017e-01 -9.48655605e-02\n  6.44334078e-01  5.66730738e-01  4.00217950e-01  3.54501128e-01\n  5.93429655e-02  3.34488191e-02  4.00766730e-01 -8.40120986e-02\n -1.62311539e-01 -1.13768649e+00  5.19918799e-01 -8.43299210e-01\n -1.53044835e-01  1.45073980e-01  1.43162179e+00  3.33226502e-01\n  9.83022451e-01  2.84479558e-01  6.30380094e-01 -1.34325683e-01\n  2.33752672e-02  4.72642779e-01 -1.88796088e-01  4.27615196e-02\n  1.33983731e-01 -4.15078074e-01 -1.09325992e-02 -6.52691901e-01\n  1.36360848e+00  4.52363133e-01  3.10676932e-01  5.38604081e-01\n  8.96106735e-02 -4.08830971e-01 -9.72041041e-02 -4.14374948e-01\n -8.41651782e-02  4.57355917e-01 -2.10567936e-02  9.83295124e-03\n  4.01877761e-02 -4.58994538e-01 -6.39786839e-01 -4.88448262e-01\n -2.37738907e-01  4.95271891e-01 -8.67969751e-01  7.51407862e-01\n  6.67581260e-01  1.26593137e+00 -7.54207373e-01  2.41049454e-01\n  2.91602731e-01 -3.22797537e-01 -2.51736045e-01  1.12973905e+00\n  1.26162201e-01 -2.69002825e-01  3.46762016e-02 -9.88203704e-01\n -9.28987384e-01  3.07557762e-01 -5.83214223e-01  8.72229785e-02\n -6.42849207e-01 -5.94732940e-01  8.27367008e-01  3.42832267e-01\n  4.17709827e-01 -3.42780918e-01 -2.07301855e-01  1.77526027e-01\n -4.59571093e-01 -4.14074540e-01 -5.95195293e-02  2.88766474e-01\n  9.85459030e-01 -7.54762292e-01  1.65900476e-02  1.17436253e-01\n -2.38272116e-01 -4.68158931e-01  2.74075717e-01  6.34949267e-01\n  6.36178255e-01  4.66696143e-01 -6.96608007e-01  7.28301764e-01\n -4.09408718e-01 -3.15389037e-01  3.42681825e-01 -1.06935060e+00\n -3.25366080e-01  8.95700157e-01  3.67984250e-02 -2.08758891e-01\n -3.70535403e-01 -2.52384782e-01 -1.25608146e-01 -4.85009670e-01\n  8.36439788e-01  1.26395965e+00  1.69358969e+00  1.08242798e+00\n -9.65776592e-02 -1.65353954e-01 -2.48274356e-01  2.42260292e-01\n -4.94954735e-01 -7.79698074e-01  8.57012928e-01 -2.31658295e-01\n  3.04627508e-01  9.86203849e-01  2.52222210e-01  1.53017983e-01\n -8.34420696e-03  4.69506621e-01 -8.81038666e-01  4.37444411e-02\n -6.31653547e-01 -6.82111502e-01  4.67531234e-02 -7.58387148e-02\n -4.60543633e-01  2.54043013e-01 -1.98236883e-01  8.86535347e-02\n  3.14951658e-01 -1.41826332e-01 -2.06058063e-02 -1.21272340e-01\n -1.11241639e+00  5.63532710e-01 -1.51829034e-01 -1.04005921e+00\n  4.26984817e-01 -4.88046050e-01 -1.58592239e-02 -6.56357110e-01\n -4.14091527e-01 -7.13776238e-03 -2.81906962e-01 -5.26906133e-01\n -5.18359020e-02 -7.05150247e-01 -7.78409719e-01  6.72235906e-01\n  1.58399135e-01  4.64723706e-01  2.42743567e-01 -2.08760053e-01\n -2.09647954e-01 -1.14171892e-01 -3.65529448e-01  4.47342664e-01\n  9.20571446e-01  7.16883123e-01  5.44878580e-02 -5.68388462e-01\n  8.73055696e-01 -7.36307502e-01  7.42545545e-01 -2.62883782e-01\n -7.62161672e-01  1.53657770e+00  1.96878076e-01 -1.04298949e-01\n  5.61690181e-02 -1.09531671e-01 -3.49120736e-01  5.40086269e-01\n  5.34687519e-01  2.29529217e-01 -1.20448947e-01  7.61992216e-01\n  1.29751503e+00 -2.74081707e-01  1.93338919e+00 -2.50032753e-01\n -8.80052984e-01  4.20654774e-01 -3.06237072e-01  2.43508235e-01\n -2.89623767e-01  3.97883743e-01  3.53961617e-01 -2.98833728e-01\n -4.46164608e-01  9.31604087e-01  1.30229485e+00  3.82109046e-01\n  1.54023051e-01 -8.09158087e-01  3.10655739e-02  4.25060570e-01\n -1.07503748e+00  8.06839883e-01  2.56977618e-01  6.86395526e-01\n -1.23976803e+00 -8.85996580e-01  7.69288182e-01 -1.02260005e+00\n -1.26676392e-02  4.44962651e-01  2.95378208e-01  6.74138486e-01\n -1.55783191e-01  7.88471460e-01  3.72361064e-01 -1.10741206e-01\n -1.16141176e+00  1.50117828e-02  3.02210510e-01  5.52206993e-01\n -2.29190007e-01  4.19014186e-01 -1.14054632e+00 -2.70786971e-01\n -6.89697564e-01 -3.66648197e-01 -4.73570764e-01 -1.22580910e+00\n -6.80086493e-01 -6.87259912e-01  2.83665985e-01  1.31302416e+00\n  1.47164688e-01  2.71172464e-01  8.44205141e-01  1.23290980e+00\n -4.87512916e-01 -1.14978468e+00 -7.83365071e-02 -9.77495238e-02\n -6.56677902e-01  1.35259792e-01 -6.68141961e-01 -2.04357052e+00\n  8.42916965e-03  8.17824364e-01 -8.73298526e-01  6.34488702e-01\n -9.35334504e-01 -5.50233901e-01 -3.68481763e-02  1.20389652e+00\n  4.41734165e-01  1.18203807e+00 -3.75343293e-01 -1.25529632e-01\n  1.28802800e+00 -3.72901827e-01 -1.66848255e-03 -2.55233079e-01\n -6.54689312e-01 -4.95871484e-01  3.55924666e-01  1.22601733e-01\n -4.19237018e-01 -7.62902319e-01  4.68618661e-01 -5.85163355e-01\n -9.88408923e-01 -1.20791197e-01  2.53062367e-01  2.18838036e-01\n  1.31369483e+00 -5.90855666e-02  2.49494851e-01  3.91888499e-01\n -8.39157224e-01  6.36945724e-01  6.42636001e-01 -3.13331299e-02\n -1.92721069e-01 -1.08594574e-01 -1.80010974e-01 -2.49706849e-01\n -6.86178505e-01  5.68155348e-01  5.99055029e-02  2.97102809e-01\n -3.77317548e-01 -1.11678457e+00  1.61587381e+00 -5.96893616e-02\n  2.68705636e-01  4.02907521e-01 -3.55145931e-01 -9.63331938e-01\n -9.13376153e-01  2.09885001e+00 -4.34491098e-01 -2.22158253e-01\n -2.19090596e-01  1.06219865e-01  5.19946456e-01  7.50994802e-01\n -5.43504953e-01  9.68418658e-01  3.24021786e-01  2.53633827e-01\n -4.21146840e-01  2.64883399e-01  1.76347554e-01 -1.95636883e-01\n  5.70220292e-01 -2.73787975e-01 -1.43592560e+00  7.99081087e-01\n -3.17269921e-01  1.01320767e+00 -1.95834503e-01  6.51590466e-01\n -4.97139513e-01 -3.59274417e-01 -1.05889097e-01 -4.11206722e-01\n -6.62109256e-01  9.88930464e-02 -1.02428460e+00  1.65216193e-01\n -2.71207184e-01 -2.22026795e-01 -5.82357943e-01  4.91212308e-01\n  5.39332449e-01  4.89868909e-01  1.10067829e-01 -8.59980583e-01\n  1.83915436e-01  1.59478664e-01  5.27693033e-01  2.07281247e-01\n -7.61109665e-02 -5.02664328e-01 -3.81678909e-01  7.17179179e-01\n -3.76311541e-01 -1.74475133e-01  1.23782325e+00 -4.15024370e-01\n  7.57846117e-01  9.07740146e-02 -7.27291822e-01 -1.54546291e-01\n  9.06881094e-02  7.69995987e-01  6.85637593e-01 -1.33231342e-01\n  7.97567904e-01 -4.51017588e-01  4.00054306e-02  3.54825377e-01\n -7.51526356e-01  2.62083501e-01  1.07493734e+00  3.02231997e-01\n -2.73282021e-01 -2.21901000e-01  6.68348968e-01 -2.53414214e-01\n -5.54432869e-02 -7.29607284e-01  1.84147012e+00  3.80382001e-01\n -7.55865097e-01  4.07638282e-01 -1.01022959e+00 -8.73635709e-01\n  6.39540315e-01  5.19992828e-01 -8.94985616e-01 -1.93435609e-01\n  1.95046678e-01 -3.61719638e-01  8.48142337e-03 -8.72141421e-01\n -1.57182679e-01  1.28155440e-01 -2.15435654e-01 -1.10107169e-01\n -3.00958395e-01  8.05247188e-01  1.06388599e-01 -5.34530431e-02\n -2.25369241e-02  2.34356508e-01 -3.69649678e-02  8.62300694e-01\n -3.97203118e-01 -3.67449224e-01 -2.23646194e-01 -2.38939345e-01\n  1.42672968e+00 -5.11308014e-01  4.29500461e-01  1.25710055e-01\n  1.94714293e-01 -9.94055033e-01  1.64247230e-02 -2.07908824e-01\n -2.86147427e-02  1.12391986e-01  3.17825049e-01  3.57378066e-01\n  4.98033583e-01 -1.11296773e+00 -8.89742076e-02 -7.96709478e-01\n -7.97189116e-01  8.26158300e-02  9.36753526e-02 -1.37266111e+00\n -1.19904017e+00  4.94985908e-01  4.38831627e-01  3.90306622e-01\n -1.03614891e+00  1.06910193e+00 -9.92183805e-01  4.16128635e-01\n  1.57411963e-01  4.37567420e-02 -5.01668930e-01 -6.34670496e-01\n  1.35282207e+00  9.31817293e-01 -5.00001907e-01  6.94113255e-01\n  6.07897997e-01  4.53028306e-02  1.97204519e-02  1.19926345e+00\n -9.76332277e-02  1.08824170e+00  1.78785458e-01 -1.05407882e+00\n -2.55459696e-01  4.80062485e-01 -8.94140244e-01  8.04582536e-01\n -5.04031420e-01 -2.53143400e-01 -3.14514428e-01  6.05707690e-02\n  8.74830246e-01 -1.49615124e-01  4.12765235e-01  6.16285264e-01\n -4.52446401e-01 -1.26870227e+00  1.96023658e-02  1.55019522e+00\n  6.21509314e-01  2.16472492e-01 -4.71864969e-01  3.36253047e-01\n  6.75724745e-01  7.95645863e-02 -3.94117475e-01  7.89096832e-01\n  2.80957699e-01 -8.19499254e-01  5.73477089e-01 -1.73762009e-01\n  9.14819181e-01 -9.75823402e-02  5.43585598e-01 -1.89940616e-01\n  5.45335114e-01  4.01494890e-01  3.66154253e-01  1.61472023e-01\n -6.29305184e-01 -3.00351709e-01 -5.05930245e-01 -1.26222241e+00\n -6.79961145e-01 -2.40593970e-01  5.25375366e-01 -4.07035172e-01\n  9.74386930e-01 -2.31867313e-01  4.71936762e-01  1.18905291e-01\n  1.51783347e+00  4.47132945e-01 -1.01456308e+00 -2.58297563e-01\n  5.30719161e-01 -5.84926486e-01 -1.88940108e+00 -4.23367083e-01\n -2.78669357e-01 -3.87933612e-01  9.62066352e-02 -1.14717734e+00\n  5.69665968e-01  2.12166488e-01 -1.52919665e-01 -9.30151105e-01\n -1.00059533e+00 -6.21362269e-01 -4.11879659e-01  2.46933699e-01\n -5.20547688e-01  5.01006782e-01  3.37458611e-01  1.07698381e-01\n  5.03715932e-01 -4.34943795e-01 -5.73150337e-01 -1.30827153e+00\n -4.69920039e-01  1.36095452e+00 -3.24573636e-01 -2.07421482e-01\n -1.44346809e+00  3.79484035e-02  4.35215265e-01 -3.30379635e-01\n  4.03389513e-01  2.01243925e+00  1.43514663e-01  1.85601130e-01\n  3.10549617e-01 -1.76172674e-01  1.16841030e+00  7.92353034e-01\n -2.39220001e-02 -2.45657548e-01  5.71039736e-01 -4.12756801e-01\n  4.97253209e-01 -4.28013593e-01  4.83225882e-01  1.03882349e+00\n -7.06242025e-01 -2.95019299e-01  5.60717344e-01  6.53518558e-01\n -6.73923910e-01  4.89431649e-01 -4.27243948e-01 -1.21300183e-02\n  1.05933416e+00 -4.64884698e-01  8.48800302e-01 -6.19819351e-02\n  3.54603748e-04  6.31850809e-02  4.75740619e-03 -4.21820104e-01\n  5.22166729e-01  1.61523008e+00 -5.53004667e-02 -3.58450770e-01\n  3.13938797e-01  2.03331951e-02  2.33957767e-01  4.41185862e-01\n -2.86167264e-01  1.58116984e+00  5.10100007e-01 -5.64187169e-02\n -1.77778780e-01 -1.66037607e+00 -4.52672631e-01  1.06379962e+00\n -8.60739291e-01 -1.32679835e-01  6.21190667e-02  3.83347154e-01\n -4.88643527e-01 -2.07089871e-01  4.84576225e-01  1.85398668e-01\n  6.31175190e-02  6.04318619e-01  1.37162256e+00  5.05514503e-01\n  3.74818034e-02 -7.75630713e-01 -1.60463858e+00 -9.30251777e-02\n  2.25357026e-01 -1.72035360e+00 -6.11739874e-01 -4.14738119e-01\n -1.13541794e+00  3.81557912e-01 -5.73186278e-01 -5.52289009e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m vect2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(text2, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     12\u001b[0m vect3 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(text3, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphrase 1 et phrase 2 : \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvect2\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphrase 1 et phrase 3 : \u001b[39m\u001b[38;5;124m\"\u001b[39m, cosine_similarity(vect, vect3))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphrase 2 et phrase 3 : \u001b[39m\u001b[38;5;124m\"\u001b[39m, cosine_similarity(vect2, vect3))\n",
      "File \u001b[1;32mc:\\Users\\hugod\\Documents\\dev\\rammus_python\\venv310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\hugod\\Documents\\dev\\rammus_python\\venv310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1657\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1613\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1614\u001b[0m \n\u001b[0;32m   1615\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1653\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1657\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1659\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\hugod\\Documents\\dev\\rammus_python\\venv310\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:164\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    155\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    156\u001b[0m         X,\n\u001b[0;32m    157\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 164\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     Y \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m    173\u001b[0m         Y,\n\u001b[0;32m    174\u001b[0m         accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    179\u001b[0m     )\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32mc:\\Users\\hugod\\Documents\\dev\\rammus_python\\venv310\\lib\\site-packages\\sklearn\\utils\\validation.py:989\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    983\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    984\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m             )\n\u001b[1;32m--> 989\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    995\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 1.94293320e-01 -2.10651219e-01 -2.45663583e-01  4.50096071e-01\n  2.51398236e-01 -8.25517178e-01  3.70970607e-01  4.05648261e-01\n  4.45635259e-01  3.17174196e-01 -7.37123668e-01  7.12277889e-01\n  8.31833124e-01 -9.75195885e-01 -4.67719913e-01 -5.42342328e-02\n -1.65470943e-01 -1.30574405e-02  1.67292401e-01 -2.00911969e-01\n  9.35625374e-01  7.70781755e-01  1.35033512e-02  1.65528715e-01\n  1.73180056e+00 -4.99150753e-01  2.14997843e-01 -3.55547547e-01\n -5.80278575e-01 -1.52904820e+00  9.06478047e-01  7.97619164e-01\n -1.28061736e+00 -4.37950157e-02  4.86372739e-01  8.81358564e-01\n -4.59378988e-01  4.17938560e-01  4.64622915e-01 -4.24909294e-01\n  1.23207617e+00  5.29266931e-02 -1.09578688e-02 -8.14341307e-02\n  7.00495690e-02  5.17972708e-01  9.88236010e-01  2.07783639e-01\n  4.26896989e-01  5.04319310e-01 -3.22461963e-01 -3.68990488e-02\n -2.64071584e-01  1.17840208e-01  7.79965937e-01  2.84064263e-01\n -1.03462243e+00 -4.13286686e-01  3.31757933e-01  2.21932039e-01\n  9.72830057e-02 -1.45220175e-01 -4.45241809e-01  5.39845467e-01\n -4.59513813e-01  1.76549464e-01 -2.38531828e-01 -3.91258746e-01\n -6.67483509e-01 -9.60243680e-03 -1.88307953e+00  4.92146552e-01\n  4.68064725e-01  7.14264929e-01 -1.00232089e+00 -1.33189440e+00\n -7.09219217e-01 -4.32485074e-01 -1.31902680e-01 -3.59311163e-01\n  2.43577417e-02 -1.20751277e-01  4.31555361e-02 -5.91750562e-01\n -3.01917922e-02 -4.84053195e-01 -7.25147367e-01  5.11856079e-02\n  6.28282487e-01  1.59070566e-01 -1.71613857e-01 -2.41314307e-01\n  6.95268035e-01 -1.21703339e+00 -7.92324021e-02  2.19056919e-01\n  9.64006186e-01  7.69332284e-03  5.19302368e-01 -1.02822995e+00\n  1.94025561e-02  7.05509186e-01 -9.62175786e-01 -6.19192421e-01\n -2.02194676e-01 -3.38242352e-01  3.22623551e-02  5.93251586e-01\n  2.08731461e-02  5.34945307e-03  6.92562342e-01  6.62296951e-01\n -6.91574454e-01  3.30411494e-01 -9.54753757e-01  1.27606437e-01\n -5.14088154e-01 -5.96677184e-01  9.99101102e-01 -1.97664574e-02\n -8.44280183e-01  1.63048059e-01 -1.88813284e-01  4.10677791e-01\n  4.86011297e-01  7.03580856e-01  2.21058279e-01  3.97054851e-01\n  2.45410308e-01 -1.18445230e+00 -3.54909569e-01 -6.23040855e-01\n -1.32707596e-01 -2.12662835e-02 -1.35669500e-01  3.76995742e-01\n  7.03804970e-01 -5.37166893e-01 -1.98757946e-01  4.30597663e-01\n  5.72494805e-01  1.40805796e-01 -2.17127442e-01 -3.26088220e-01\n -6.88603401e-01  6.94000065e-01  2.47398004e-01 -2.26765394e-01\n  4.00792480e-01 -1.49014980e-01 -1.20922662e-02  1.41874626e-01\n -2.62499660e-01 -8.40344667e-01  2.85539836e-01 -1.00684154e+00\n -2.89785147e-01 -5.88097751e-01 -4.90014702e-02 -1.09425284e-01\n  3.29142511e-01 -2.52799094e-01 -6.03153229e-01  1.12131730e-01\n -9.23459232e-02  1.15764700e-01  3.52418453e-01 -6.96424663e-01\n  1.69107497e-01 -1.13010816e-02  3.44364017e-01 -9.48655605e-02\n  6.44334078e-01  5.66730738e-01  4.00217950e-01  3.54501128e-01\n  5.93429655e-02  3.34488191e-02  4.00766730e-01 -8.40120986e-02\n -1.62311539e-01 -1.13768649e+00  5.19918799e-01 -8.43299210e-01\n -1.53044835e-01  1.45073980e-01  1.43162179e+00  3.33226502e-01\n  9.83022451e-01  2.84479558e-01  6.30380094e-01 -1.34325683e-01\n  2.33752672e-02  4.72642779e-01 -1.88796088e-01  4.27615196e-02\n  1.33983731e-01 -4.15078074e-01 -1.09325992e-02 -6.52691901e-01\n  1.36360848e+00  4.52363133e-01  3.10676932e-01  5.38604081e-01\n  8.96106735e-02 -4.08830971e-01 -9.72041041e-02 -4.14374948e-01\n -8.41651782e-02  4.57355917e-01 -2.10567936e-02  9.83295124e-03\n  4.01877761e-02 -4.58994538e-01 -6.39786839e-01 -4.88448262e-01\n -2.37738907e-01  4.95271891e-01 -8.67969751e-01  7.51407862e-01\n  6.67581260e-01  1.26593137e+00 -7.54207373e-01  2.41049454e-01\n  2.91602731e-01 -3.22797537e-01 -2.51736045e-01  1.12973905e+00\n  1.26162201e-01 -2.69002825e-01  3.46762016e-02 -9.88203704e-01\n -9.28987384e-01  3.07557762e-01 -5.83214223e-01  8.72229785e-02\n -6.42849207e-01 -5.94732940e-01  8.27367008e-01  3.42832267e-01\n  4.17709827e-01 -3.42780918e-01 -2.07301855e-01  1.77526027e-01\n -4.59571093e-01 -4.14074540e-01 -5.95195293e-02  2.88766474e-01\n  9.85459030e-01 -7.54762292e-01  1.65900476e-02  1.17436253e-01\n -2.38272116e-01 -4.68158931e-01  2.74075717e-01  6.34949267e-01\n  6.36178255e-01  4.66696143e-01 -6.96608007e-01  7.28301764e-01\n -4.09408718e-01 -3.15389037e-01  3.42681825e-01 -1.06935060e+00\n -3.25366080e-01  8.95700157e-01  3.67984250e-02 -2.08758891e-01\n -3.70535403e-01 -2.52384782e-01 -1.25608146e-01 -4.85009670e-01\n  8.36439788e-01  1.26395965e+00  1.69358969e+00  1.08242798e+00\n -9.65776592e-02 -1.65353954e-01 -2.48274356e-01  2.42260292e-01\n -4.94954735e-01 -7.79698074e-01  8.57012928e-01 -2.31658295e-01\n  3.04627508e-01  9.86203849e-01  2.52222210e-01  1.53017983e-01\n -8.34420696e-03  4.69506621e-01 -8.81038666e-01  4.37444411e-02\n -6.31653547e-01 -6.82111502e-01  4.67531234e-02 -7.58387148e-02\n -4.60543633e-01  2.54043013e-01 -1.98236883e-01  8.86535347e-02\n  3.14951658e-01 -1.41826332e-01 -2.06058063e-02 -1.21272340e-01\n -1.11241639e+00  5.63532710e-01 -1.51829034e-01 -1.04005921e+00\n  4.26984817e-01 -4.88046050e-01 -1.58592239e-02 -6.56357110e-01\n -4.14091527e-01 -7.13776238e-03 -2.81906962e-01 -5.26906133e-01\n -5.18359020e-02 -7.05150247e-01 -7.78409719e-01  6.72235906e-01\n  1.58399135e-01  4.64723706e-01  2.42743567e-01 -2.08760053e-01\n -2.09647954e-01 -1.14171892e-01 -3.65529448e-01  4.47342664e-01\n  9.20571446e-01  7.16883123e-01  5.44878580e-02 -5.68388462e-01\n  8.73055696e-01 -7.36307502e-01  7.42545545e-01 -2.62883782e-01\n -7.62161672e-01  1.53657770e+00  1.96878076e-01 -1.04298949e-01\n  5.61690181e-02 -1.09531671e-01 -3.49120736e-01  5.40086269e-01\n  5.34687519e-01  2.29529217e-01 -1.20448947e-01  7.61992216e-01\n  1.29751503e+00 -2.74081707e-01  1.93338919e+00 -2.50032753e-01\n -8.80052984e-01  4.20654774e-01 -3.06237072e-01  2.43508235e-01\n -2.89623767e-01  3.97883743e-01  3.53961617e-01 -2.98833728e-01\n -4.46164608e-01  9.31604087e-01  1.30229485e+00  3.82109046e-01\n  1.54023051e-01 -8.09158087e-01  3.10655739e-02  4.25060570e-01\n -1.07503748e+00  8.06839883e-01  2.56977618e-01  6.86395526e-01\n -1.23976803e+00 -8.85996580e-01  7.69288182e-01 -1.02260005e+00\n -1.26676392e-02  4.44962651e-01  2.95378208e-01  6.74138486e-01\n -1.55783191e-01  7.88471460e-01  3.72361064e-01 -1.10741206e-01\n -1.16141176e+00  1.50117828e-02  3.02210510e-01  5.52206993e-01\n -2.29190007e-01  4.19014186e-01 -1.14054632e+00 -2.70786971e-01\n -6.89697564e-01 -3.66648197e-01 -4.73570764e-01 -1.22580910e+00\n -6.80086493e-01 -6.87259912e-01  2.83665985e-01  1.31302416e+00\n  1.47164688e-01  2.71172464e-01  8.44205141e-01  1.23290980e+00\n -4.87512916e-01 -1.14978468e+00 -7.83365071e-02 -9.77495238e-02\n -6.56677902e-01  1.35259792e-01 -6.68141961e-01 -2.04357052e+00\n  8.42916965e-03  8.17824364e-01 -8.73298526e-01  6.34488702e-01\n -9.35334504e-01 -5.50233901e-01 -3.68481763e-02  1.20389652e+00\n  4.41734165e-01  1.18203807e+00 -3.75343293e-01 -1.25529632e-01\n  1.28802800e+00 -3.72901827e-01 -1.66848255e-03 -2.55233079e-01\n -6.54689312e-01 -4.95871484e-01  3.55924666e-01  1.22601733e-01\n -4.19237018e-01 -7.62902319e-01  4.68618661e-01 -5.85163355e-01\n -9.88408923e-01 -1.20791197e-01  2.53062367e-01  2.18838036e-01\n  1.31369483e+00 -5.90855666e-02  2.49494851e-01  3.91888499e-01\n -8.39157224e-01  6.36945724e-01  6.42636001e-01 -3.13331299e-02\n -1.92721069e-01 -1.08594574e-01 -1.80010974e-01 -2.49706849e-01\n -6.86178505e-01  5.68155348e-01  5.99055029e-02  2.97102809e-01\n -3.77317548e-01 -1.11678457e+00  1.61587381e+00 -5.96893616e-02\n  2.68705636e-01  4.02907521e-01 -3.55145931e-01 -9.63331938e-01\n -9.13376153e-01  2.09885001e+00 -4.34491098e-01 -2.22158253e-01\n -2.19090596e-01  1.06219865e-01  5.19946456e-01  7.50994802e-01\n -5.43504953e-01  9.68418658e-01  3.24021786e-01  2.53633827e-01\n -4.21146840e-01  2.64883399e-01  1.76347554e-01 -1.95636883e-01\n  5.70220292e-01 -2.73787975e-01 -1.43592560e+00  7.99081087e-01\n -3.17269921e-01  1.01320767e+00 -1.95834503e-01  6.51590466e-01\n -4.97139513e-01 -3.59274417e-01 -1.05889097e-01 -4.11206722e-01\n -6.62109256e-01  9.88930464e-02 -1.02428460e+00  1.65216193e-01\n -2.71207184e-01 -2.22026795e-01 -5.82357943e-01  4.91212308e-01\n  5.39332449e-01  4.89868909e-01  1.10067829e-01 -8.59980583e-01\n  1.83915436e-01  1.59478664e-01  5.27693033e-01  2.07281247e-01\n -7.61109665e-02 -5.02664328e-01 -3.81678909e-01  7.17179179e-01\n -3.76311541e-01 -1.74475133e-01  1.23782325e+00 -4.15024370e-01\n  7.57846117e-01  9.07740146e-02 -7.27291822e-01 -1.54546291e-01\n  9.06881094e-02  7.69995987e-01  6.85637593e-01 -1.33231342e-01\n  7.97567904e-01 -4.51017588e-01  4.00054306e-02  3.54825377e-01\n -7.51526356e-01  2.62083501e-01  1.07493734e+00  3.02231997e-01\n -2.73282021e-01 -2.21901000e-01  6.68348968e-01 -2.53414214e-01\n -5.54432869e-02 -7.29607284e-01  1.84147012e+00  3.80382001e-01\n -7.55865097e-01  4.07638282e-01 -1.01022959e+00 -8.73635709e-01\n  6.39540315e-01  5.19992828e-01 -8.94985616e-01 -1.93435609e-01\n  1.95046678e-01 -3.61719638e-01  8.48142337e-03 -8.72141421e-01\n -1.57182679e-01  1.28155440e-01 -2.15435654e-01 -1.10107169e-01\n -3.00958395e-01  8.05247188e-01  1.06388599e-01 -5.34530431e-02\n -2.25369241e-02  2.34356508e-01 -3.69649678e-02  8.62300694e-01\n -3.97203118e-01 -3.67449224e-01 -2.23646194e-01 -2.38939345e-01\n  1.42672968e+00 -5.11308014e-01  4.29500461e-01  1.25710055e-01\n  1.94714293e-01 -9.94055033e-01  1.64247230e-02 -2.07908824e-01\n -2.86147427e-02  1.12391986e-01  3.17825049e-01  3.57378066e-01\n  4.98033583e-01 -1.11296773e+00 -8.89742076e-02 -7.96709478e-01\n -7.97189116e-01  8.26158300e-02  9.36753526e-02 -1.37266111e+00\n -1.19904017e+00  4.94985908e-01  4.38831627e-01  3.90306622e-01\n -1.03614891e+00  1.06910193e+00 -9.92183805e-01  4.16128635e-01\n  1.57411963e-01  4.37567420e-02 -5.01668930e-01 -6.34670496e-01\n  1.35282207e+00  9.31817293e-01 -5.00001907e-01  6.94113255e-01\n  6.07897997e-01  4.53028306e-02  1.97204519e-02  1.19926345e+00\n -9.76332277e-02  1.08824170e+00  1.78785458e-01 -1.05407882e+00\n -2.55459696e-01  4.80062485e-01 -8.94140244e-01  8.04582536e-01\n -5.04031420e-01 -2.53143400e-01 -3.14514428e-01  6.05707690e-02\n  8.74830246e-01 -1.49615124e-01  4.12765235e-01  6.16285264e-01\n -4.52446401e-01 -1.26870227e+00  1.96023658e-02  1.55019522e+00\n  6.21509314e-01  2.16472492e-01 -4.71864969e-01  3.36253047e-01\n  6.75724745e-01  7.95645863e-02 -3.94117475e-01  7.89096832e-01\n  2.80957699e-01 -8.19499254e-01  5.73477089e-01 -1.73762009e-01\n  9.14819181e-01 -9.75823402e-02  5.43585598e-01 -1.89940616e-01\n  5.45335114e-01  4.01494890e-01  3.66154253e-01  1.61472023e-01\n -6.29305184e-01 -3.00351709e-01 -5.05930245e-01 -1.26222241e+00\n -6.79961145e-01 -2.40593970e-01  5.25375366e-01 -4.07035172e-01\n  9.74386930e-01 -2.31867313e-01  4.71936762e-01  1.18905291e-01\n  1.51783347e+00  4.47132945e-01 -1.01456308e+00 -2.58297563e-01\n  5.30719161e-01 -5.84926486e-01 -1.88940108e+00 -4.23367083e-01\n -2.78669357e-01 -3.87933612e-01  9.62066352e-02 -1.14717734e+00\n  5.69665968e-01  2.12166488e-01 -1.52919665e-01 -9.30151105e-01\n -1.00059533e+00 -6.21362269e-01 -4.11879659e-01  2.46933699e-01\n -5.20547688e-01  5.01006782e-01  3.37458611e-01  1.07698381e-01\n  5.03715932e-01 -4.34943795e-01 -5.73150337e-01 -1.30827153e+00\n -4.69920039e-01  1.36095452e+00 -3.24573636e-01 -2.07421482e-01\n -1.44346809e+00  3.79484035e-02  4.35215265e-01 -3.30379635e-01\n  4.03389513e-01  2.01243925e+00  1.43514663e-01  1.85601130e-01\n  3.10549617e-01 -1.76172674e-01  1.16841030e+00  7.92353034e-01\n -2.39220001e-02 -2.45657548e-01  5.71039736e-01 -4.12756801e-01\n  4.97253209e-01 -4.28013593e-01  4.83225882e-01  1.03882349e+00\n -7.06242025e-01 -2.95019299e-01  5.60717344e-01  6.53518558e-01\n -6.73923910e-01  4.89431649e-01 -4.27243948e-01 -1.21300183e-02\n  1.05933416e+00 -4.64884698e-01  8.48800302e-01 -6.19819351e-02\n  3.54603748e-04  6.31850809e-02  4.75740619e-03 -4.21820104e-01\n  5.22166729e-01  1.61523008e+00 -5.53004667e-02 -3.58450770e-01\n  3.13938797e-01  2.03331951e-02  2.33957767e-01  4.41185862e-01\n -2.86167264e-01  1.58116984e+00  5.10100007e-01 -5.64187169e-02\n -1.77778780e-01 -1.66037607e+00 -4.52672631e-01  1.06379962e+00\n -8.60739291e-01 -1.32679835e-01  6.21190667e-02  3.83347154e-01\n -4.88643527e-01 -2.07089871e-01  4.84576225e-01  1.85398668e-01\n  6.31175190e-02  6.04318619e-01  1.37162256e+00  5.05514503e-01\n  3.74818034e-02 -7.75630713e-01 -1.60463858e+00 -9.30251777e-02\n  2.25357026e-01 -1.72035360e+00 -6.11739874e-01 -4.14738119e-01\n -1.13541794e+00  3.81557912e-01 -5.73186278e-01 -5.52289009e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from torch import Tensor, nn, cat\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "model = SentenceTransformer('symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli')\n",
    "\n",
    "text = \"bonjour je veux être content et faire du volley ainsi que de la musique\"\n",
    "text2 = \"je veux être content et faire du volley ainsi que de la musique\"\n",
    "text3 = \"J'ai fait un prêt à la banque pour acheter une voiture\"\n",
    "vect = model.encode(text, convert_to_tensor=True)\n",
    "vect2 = model.encode(text2, convert_to_tensor=True)\n",
    "vect3 = model.encode(text3, convert_to_tensor=True)\n",
    "\n",
    "print(\"phrase 1 et phrase 2 : \", cosine_similarity(vect, vect2))\n",
    "print(\"phrase 1 et phrase 3 : \", cosine_similarity(vect, vect3))\n",
    "print(\"phrase 2 et phrase 3 : \", cosine_similarity(vect2, vect3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
